{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the relevant modules to be used\n",
    "import gzip\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import struct\n",
    "import random\n",
    "from timeit import default_timer as timer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Handwritten digit recognition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is a study on the performance of Linear Regression and K-Nearest Neighbors methods in the task of classifying handwritten digits. This study is motivated by the exercise 2.8 of *Elements of Statistical learning* book. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The MNIST Database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset we're going to use for this exercise is the [MNIST handwritten digit database](http://yann.lecun.com/exdb/mnist/). Here are a few things to know about the data:\n",
    "\n",
    "- It has a training set of 60,000 examples, and a test set of 10,000 examples. \n",
    "\n",
    "- The images and the labels are in separate files, both of them following a format known as IDX, which looks like this:\n",
    "\n",
    "```\n",
    "magic number \n",
    "size in dimension 0 \n",
    "size in dimension 1 \n",
    "size in dimension 2 \n",
    "..... \n",
    "size in dimension N \n",
    "data\n",
    "```\n",
    "\n",
    "- The magic number is a 4-bytes integer: the first two bytes are always 0; the 3rd byte codes the type of data, in this case, it will always be 0x08 (which holds for unsigned byte); the 4th byte represents the dimension of the data, which is 3 for the images file (number of images x height x width) and 1 for the labels file (number of labels)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the dataset\n",
    "\n",
    "This is a possible implementation for loading the MNIST dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(field, expected, actual):\n",
    "    \"\"\"Helper function to validate file metadata.\"\"\"\n",
    "    if expected != actual:\n",
    "        raise Exception('Invalid ' + field + '. Expected ' + str(expected) + ' but got ' + str(actual))\n",
    "\n",
    "def read_next_int(reader):\n",
    "    \"\"\"Reads the next 4 bytes of a buffer and casts to integer. It assumes big-endian order.\"\"\"\n",
    "    return struct.unpack('>I', reader.read(4))[0]\n",
    "\n",
    "def load_images(path, samples):\n",
    "    \"\"\"Load a dataset of images into a matrix with <samples> rows, where each row <i> contains 28*28 elements\n",
    "    representing the pixels of the <ith> image of that dataset. Each pixel is a unsigned int, which means it\n",
    "    can take values from 0 (white) up to 255 (black).\n",
    "    \"\"\"\n",
    "    with gzip.open(path) as gz:\n",
    "        validate('magic number', 0x0803, read_next_int(gz))            \n",
    "        validate('number of samples', samples, read_next_int(gz))\n",
    "        validate('image resolution', [28, 28], [read_next_int(gz), read_next_int(gz)])            \n",
    "        images = np.frombuffer(gz.read(samples * 28 * 28), dtype = np.uint8)\n",
    "    return images.reshape((samples, 28 * 28))                \n",
    "        \n",
    "def load_labels(path, samples):    \n",
    "    \"\"\"Load the dataset of labels into a matrix with <samples> rows, where each row <i> contains 1 element\n",
    "    representing the label of the <ith> image of the corresponding image dataset. Each label can be either\n",
    "    0, 1, 2, 3, 4, 5, 6, 7, 8 or 9.\n",
    "    \"\"\"\n",
    "    with gzip.open(path) as gz:\n",
    "        validate('magic number', 0x801, read_next_int(gz))\n",
    "        validate('number of samples', samples, read_next_int(gz))        \n",
    "        labels = np.frombuffer(gz.read(samples), dtype = np.uint8)\n",
    "    return labels.reshape((samples, 1))\n",
    "\n",
    "def load_dataset(images_data_path, labels_data_path, samples):\n",
    "    \"\"\"Loads both images and labels files into a single matrix with <samples> rows, where each row contains\n",
    "    28*28 + 1 elements, where the first 28*28 elements are the pixels of the image and the last element is \n",
    "    the label for that image.\n",
    "    \"\"\"\n",
    "    images = load_images(images_data_path, samples)\n",
    "    labels = load_labels(labels_data_path, samples)\n",
    "    return np.hstack((images, labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded training data!\n",
      "[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   3  18  18  18 126 136 175  26 166 255\n",
      " 247 127   0   0   0   0   0   0   0   0   0   0   0   0  30  36  94 154\n",
      " 170 253 253 253 253 253 225 172 253 242 195  64   0   0   0   0   0   0\n",
      "   0   0   0   0   0  49 238 253 253 253 253 253 253 253 253 251  93  82\n",
      "  82  56  39   0   0   0   0   0   0   0   0   0   0   0   0  18 219 253\n",
      " 253 253 253 253 198 182 247 241   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0  80 156 107 253 253 205  11   0  43 154\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0  14   1 154 253  90   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0 139 253 190   2   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0  11 190 253  70   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  35 241\n",
      " 225 160 108   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0  81 240 253 253 119  25   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0  45 186 253 253 150  27   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0  16  93 252 253 187\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0 249 253 249  64   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0  46 130 183 253\n",
      " 253 207   2   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0  39 148 229 253 253 253 250 182   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0  24 114 221 253 253 253\n",
      " 253 201  78   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0  23  66 213 253 253 253 253 198  81   2   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0  18 171 219 253 253 253 253 195\n",
      "  80   9   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "  55 172 226 253 253 253 253 244 133  11   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0 136 253 253 253 212 135 132  16\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   5]\n",
      "\n",
      "\n",
      " Loaded test data\n",
      "[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0  84 185 159 151  60  36   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0 222 254 254 254\n",
      " 254 241 198 198 198 198 198 198 198 198 170  52   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0  67 114  72 114 163 227 254 225 254 254 254 250\n",
      " 229 254 254 140   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0  17  66  14  67  67  67  59  21 236 254 106   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0  83 253 209  18   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0  22 233 255  83   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0 129 254 238  44   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0  59 249 254  62   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0 133 254 187   5   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   9 205 248  58   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0 126 254 182   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0  75 251 240  57\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0  19 221 254 166   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   3 203 254 219\n",
      "  35   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0  38 254 254  77   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  31 224 254\n",
      " 115   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0 133 254 254  52   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  61 242\n",
      " 254 254  52   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0 121 254 254 219  40   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      " 121 254 207  18   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   7]\n"
     ]
    }
   ],
   "source": [
    "# Loading the training and test dataset\n",
    "\n",
    "training_dataset = load_dataset(\"data/training_images_idx3_ubyte.gz\", \"data/training_labels_idx1_ubyte.gz\", 60000)\n",
    "print(\"Loaded training data!\")\n",
    "\n",
    "# Prints the first image of the training set. Looking at the output, we know from the last element that this is a 5\n",
    "print(training_dataset[0]) \n",
    "\n",
    "test_dataset  = load_dataset(\"data/test_images_idx3_ubyte.gz\", \"data/test_labels_idx1_ubyte.gz\", 10000)\n",
    "print(\"\\n\\n Loaded test data\")\n",
    "\n",
    "# ...And this is a 7\n",
    "print(test_dataset[0]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing the image dataset\n",
    "\n",
    "Now that we know how to load the dataset to our program, it would be cool to visualize some of the images to see how it looks like. A function that renders a random image from the dataset could be implemented like below: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "def render_random_image(dataset):    \n",
    "    \"\"\"Renders a random image from the given dataset\"\"\"\n",
    "    random_sample = random.randint(0, len(dataset))     \n",
    "    plt.imshow(dataset[random_sample,:-1].reshape(28,28), cmap=\"gray_r\") # removes the label (last element) and reshapes to 28x28 pixels\n",
    "    plt.axis('off')\n",
    "    print(\"Sample number: #\", random_sample)\n",
    "    print(\"Image Label: \", dataset[random_sample,-1])\n",
    "    print(\"Image classification: \", classify_image(dataset[random_sample,:-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample number: # 55983\n",
      "Image Label:  4\n",
      "Image classification:  4\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "render_random_image(training_dataset) # samples 1 of the 60k images from the training dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear regression\n",
    "\n",
    "Let `N` be the number of samples in the training set, `p` be the input space dimension (in this case, 28*28 = 784) and `X` the N x p input matrix. Our linear regression function is given by:\n",
    "\n",
    "$$\\hat{Y} = X^T \\hat\\beta,$$\n",
    "\n",
    "where \n",
    "$$\\hat\\beta = (X^T X)^{-1}X^TY$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataset_for_digit(n):\n",
    "    dataset = np.copy(training_dataset)\n",
    "    for sample in dataset:\n",
    "        if sample[784] == n:\n",
    "            sample[784] = 1\n",
    "        else:\n",
    "            sample[784] = 0               \n",
    "    return dataset    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_beta(X, Y):\n",
    "    # Q, R = np.linalg.qr(X)\n",
    "    # return np.linalg.inv(R).dot(Q.T).dot(Y)    \n",
    "    return np.linalg.lstsq(X,Y, rcond=None)[0]\n",
    "    \n",
    "def linear_regression(X, beta):\n",
    "    [y] = X.T.dot(beta)  \n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_betas():\n",
    "    betas = []\n",
    "    for i in range(9):\n",
    "        digit_dataset = dataset_for_digit(i)\n",
    "        digit_beta = compute_beta(digit_dataset[:, :-1], digit_dataset[:, -1:])\n",
    "        betas.append(digit_beta)\n",
    "    return betas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to compute betas: 17.77 seconds\n"
     ]
    }
   ],
   "source": [
    "start = timer()\n",
    "betas = compute_betas()\n",
    "end = timer()\n",
    "\n",
    "print(\"Time to compute betas: {:.2f} seconds\".format(end - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_image(image):\n",
    "    scores = []\n",
    "    for beta in betas:\n",
    "        scores.append(linear_regression(image, beta))\n",
    "    return scores.index(max(scores))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
